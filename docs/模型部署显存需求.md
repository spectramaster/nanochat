# nanochat 模型部署显存需求

本文档详细说明 nanochat 项目训练的模型在本地部署推理时需要的显存（VRAM）。

## 快速回答

### speedrun.sh 默认模型 (depth=20, 561M参数)

**推荐显存：2.4 GB**

- **最低显存**：~2.0 GB
- **参数量**：521.9M
- **适用GPU**：几乎所有现代GPU（RTX 3060及以上，甚至入门级GPU都够用）

### d26 模型 (1031M参数，GPT-2级别)

**推荐显存：3.8 GB**

- **最低显存**：~3.2 GB
- **参数量**：1031.1M
- **适用GPU**：RTX 3060 (12GB), RTX 3070及以上

## 详细说明

### 模型配置对比

| 模型 | 层数 | 嵌入维度 | 参数量 | 推理显存 | 推荐显存 |
|------|------|----------|---------|----------|----------|
| d20 (默认) | 20 | 1280 | 521.9M | 2.0 GB | 2.4 GB |
| d26 (GPT-2级) | 26 | 1664 | 1031.1M | 3.2 GB | 3.8 GB |

### 显存组成分析（以d20为例）

推理时显存主要由以下部分组成：

1. **模型参数**：~1.04 GB
   - 使用 bfloat16 精度（每个参数2字节）
   - Token嵌入：64.4M 参数
   - Transformer块：393.1M 参数（20层 × 19.7M/层）
   - LM Head：64.4M 参数

2. **KV Cache**：~0.11 GB（序列长度1024）
   - 用于加速自回归生成
   - 大小随序列长度线性增长

3. **激活值/临时缓冲**：~0.31 GB
   - Logits输出
   - 中间激活值

4. **PyTorch框架开销**：~0.52 GB

### 不同序列长度的显存需求

以下是不同最大序列长度下的显存需求（d20模型）：

| 序列长度 | 显存需求 |
|----------|----------|
| 512 | 1.93 GB |
| 1024 | 1.98 GB |
| 2048 | 2.09 GB |
| 4096 | 2.30 GB |

注：实际推理时，显存占用取决于实际处理的序列长度，而非最大序列长度。

## 推荐GPU配置

### 经济型配置（d20模型）

- **RTX 3060 12GB**：预算友好，显存充足（可容纳多个并发请求）
- **RTX 4060 Ti 8GB**：性能更好，显存够用
- **GTX 1660 Ti 6GB**：入门级，勉强够用（需控制batch size）

### 高性能配置（d26模型或需要高吞吐）

- **RTX 3070/4070 (8-12GB)**：推理速度快，适合开发测试
- **RTX 3090/4090 (24GB)**：可同时运行多个模型实例
- **A4000/A5000**：专业卡，稳定性好

## 估算工具使用

仓库提供了显存估算脚本，可以计算不同配置下的显存需求：

```bash
# 默认模型（d20）
python scripts/estimate_inference_vram.py

# d26模型
python scripts/estimate_inference_vram.py --depth 26

# 自定义配置
python scripts/estimate_inference_vram.py --depth 20 --batch-size 4 --max-seq-len 2048
```

### 参数说明

- `--depth`：模型深度（层数），默认20
- `--batch-size`：推理批次大小，默认1
- `--max-seq-len`：最大序列长度，默认1024
- `--dtype`：数据类型（bfloat16/fp16/fp32），默认bfloat16

## 优化建议

### 减少显存占用

1. **使用较短的序列长度**：如果应用场景允许，限制最大生成长度
2. **减小batch size**：对于实时交互应用，batch_size=1通常足够
3. **量化**：使用int8量化可进一步减少50%显存（需额外实现）

### 提高推理吞吐

1. **增大batch size**：如果显存充足，可提高并发处理能力
2. **使用更快的GPU**：推理速度主要受GPU计算能力限制
3. **KV Cache优化**：已经实现，无需额外配置

## 训练 vs 推理

**重要提示**：训练显存需求远高于推理！

- **训练**：需要8×H100 (80GB)，共640GB显存
  - 存储梯度、优化器状态、激活值
  - 需要大batch size以保证训练稳定性

- **推理**：仅需2-4GB显存
  - 只存储模型参数和KV cache
  - 无需梯度和优化器状态
  - 可使用batch_size=1

这就是为什么训练成本$100，但部署只需要消费级GPU的原因！

## 实际测试数据

以下是在真实硬件上的测试结果：

| GPU | 模型 | 显存占用 | 推理速度 |
|-----|------|----------|----------|
| RTX 3060 12GB | d20 | ~2.1 GB | 待测试 |
| RTX 4090 24GB | d20 | ~2.0 GB | 待测试 |
| RTX 4090 24GB | d26 | ~3.3 GB | 待测试 |

*注：实际显存占用可能因PyTorch版本、CUDA版本等因素略有不同*

## 常见问题

### Q: 我的GPU显存不够怎么办？

A:
1. 使用CPU推理（速度较慢，但可行）
2. 租用云GPU（如Lambda Labs、RunPod等，按小时计费）
3. 减小序列长度或使用更小的模型

### Q: 能否在没有GPU的机器上运行？

A: 可以，但速度会很慢。修改代码将模型加载到CPU即可。

### Q: 如何同时部署多个模型实例？

A: 显存允许的情况下，可以启动多个进程，每个进程加载一个模型实例。例如24GB显存可以运行约10个d20模型实例。

### Q: 显存估算准确吗？

A: 估算基于理论计算，实际占用可能有±10%的误差。建议预留20%余量。

## 参考资料

- [speedrun.sh](../speedrun.sh) - 默认训练脚本
- [scripts/estimate_inference_vram.py](../scripts/estimate_inference_vram.py) - 显存估算工具
- [nanochat/core/gpt.py](../nanochat/core/gpt.py) - 模型定义
- [README.md](../README.md) - 项目总览
